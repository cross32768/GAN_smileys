{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzuk\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:888: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    }
   ],
   "source": [
    "DIRNAME = 'smileys_dataset_all_update/'\n",
    "SIZE = 32\n",
    "CHANNEL = 3\n",
    "files = os.listdir(DIRNAME)\n",
    "N_data = len(files) * 2\n",
    "train_data = np.zeros((N_data, SIZE, SIZE, CHANNEL))\n",
    "for i,file in enumerate(files):\n",
    "    im = Image.open(DIRNAME + file).convert('RGB').resize((SIZE, SIZE))\n",
    "    train_data[i] = np.array(im).astype(np.float32).reshape(SIZE,SIZE,CHANNEL)\n",
    "    train_data[i+len(files)] = train_data[i][:,::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_noise = 100\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim = N_noise))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128 * 8 * 8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((128, 8, 8)))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size = 5, strides = 1, padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(3, kernel_size = 5, strides = 1, padding = 'same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size = 5, strides = 2, padding = 'same', input_shape = (CHANNEL, SIZE, SIZE)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Conv2D(128, kernel_size = 5, strides = 2))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "HALF_BATCH = int(BATCH_SIZE/2)\n",
    "NUM_EPOCH = 5000\n",
    "GENERATED_IMAGE_PATH = 'generated_images16/'\n",
    "if not os.path.exists(GENERATED_IMAGE_PATH):\n",
    "    os.mkdir(GENERATED_IMAGE_PATH)\n",
    "\n",
    "def train():\n",
    "    X_train = (train_data - 127.5) / 127.5\n",
    "    X_train = X_train.reshape(N_data, CHANNEL, SIZE, SIZE)\n",
    "    discriminator = discriminator_model()\n",
    "    # opt_d = SGD(lr = 5e-4, momentum = 0.9, nesterov = True)\n",
    "    opt_d = Adam(lr = 1e-5, beta_1 = 0.1)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=opt_d)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    generator = generator_model()\n",
    "    dcgan = Sequential([generator, discriminator])\n",
    "    opt_g = Adam(lr = 2e-5, beta_1 = 0.5)    \n",
    "    dcgan.compile(loss='binary_crossentropy', optimizer=opt_g)\n",
    "    \n",
    "    num_batches = int(N_data / BATCH_SIZE)\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        \n",
    "        for index in range(num_batches):\n",
    "            noise = np.array([np.random.uniform(-1, 1, N_noise) for _ in range(HALF_BATCH)])\n",
    "            #noise = np.array([np.random.normal(0, 1, N_noise) for _ in range(HALF_BATCH)])\n",
    "            image_batch = X_train[np.random.randint(0, N_data,HALF_BATCH)]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "        \n",
    "            if index == num_batches - 1 and epoch % 100 == 0:\n",
    "                for n,image in enumerate(generated_images):\n",
    "                    image = image*127.5 + 127.5\n",
    "                    Image.fromarray(image.astype(np.uint8).reshape(SIZE,SIZE,CHANNEL)) \\\n",
    "                                                      .save(GENERATED_IMAGE_PATH+\"%03d_%03d.png\" % (epoch, n))\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(image_batch, np.random.uniform(1, 1,HALF_BATCH))\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, np.random.uniform(0, 0, HALF_BATCH))\n",
    "            noise = np.array([np.random.uniform(-1, 1, N_noise) for _ in range(BATCH_SIZE)])\n",
    "            #noise = np.array([np.random.normal(0, 1, N_noise) for _ in range(BATCH_SIZE)])\n",
    "            g_loss = dcgan.train_on_batch(noise, np.random.uniform(1, 1, BATCH_SIZE))\n",
    "            if index  == num_batches - 1:\n",
    "                print(\"epoch: %d, batch: %d, g_loss: %f, d_loss_real: %f, d_loss_fake: %f\" % (epoch, index, g_loss, d_loss_real, d_loss_fake))\n",
    "    generator.save_weights('generator16.h5')\n",
    "    discriminator.save_weights('discriminator16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzuk\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 144, g_loss: 1.262308, d_loss_real: 0.062978, d_loss_fake: 0.256880\n",
      "epoch: 1, batch: 144, g_loss: 1.487672, d_loss_real: 0.016219, d_loss_fake: 0.225390\n",
      "epoch: 2, batch: 144, g_loss: 1.885019, d_loss_real: 0.000099, d_loss_fake: 0.150956\n",
      "epoch: 3, batch: 144, g_loss: 2.422510, d_loss_real: 0.000326, d_loss_fake: 0.101533\n",
      "epoch: 4, batch: 144, g_loss: 1.846790, d_loss_real: 0.018173, d_loss_fake: 0.126277\n",
      "epoch: 5, batch: 144, g_loss: 1.173297, d_loss_real: 0.017878, d_loss_fake: 0.127066\n",
      "epoch: 6, batch: 144, g_loss: 0.855663, d_loss_real: 0.298574, d_loss_fake: 0.950694\n",
      "epoch: 7, batch: 144, g_loss: 1.442067, d_loss_real: 0.164540, d_loss_fake: 0.357075\n",
      "epoch: 8, batch: 144, g_loss: 1.687504, d_loss_real: 0.219216, d_loss_fake: 0.233889\n",
      "epoch: 9, batch: 144, g_loss: 1.084283, d_loss_real: 0.160102, d_loss_fake: 0.558669\n",
      "epoch: 10, batch: 144, g_loss: 1.506993, d_loss_real: 0.362313, d_loss_fake: 0.228347\n",
      "epoch: 11, batch: 144, g_loss: 1.503734, d_loss_real: 0.501780, d_loss_fake: 0.177200\n",
      "epoch: 12, batch: 144, g_loss: 1.907975, d_loss_real: 0.074891, d_loss_fake: 0.310753\n",
      "epoch: 13, batch: 144, g_loss: 1.832186, d_loss_real: 0.195606, d_loss_fake: 0.254397\n",
      "epoch: 14, batch: 144, g_loss: 1.530526, d_loss_real: 0.121064, d_loss_fake: 0.424756\n",
      "epoch: 15, batch: 144, g_loss: 1.308190, d_loss_real: 0.669317, d_loss_fake: 0.499811\n",
      "epoch: 16, batch: 144, g_loss: 1.084433, d_loss_real: 0.545957, d_loss_fake: 0.617611\n",
      "epoch: 17, batch: 144, g_loss: 1.046889, d_loss_real: 0.351821, d_loss_fake: 0.620636\n",
      "epoch: 18, batch: 144, g_loss: 1.112549, d_loss_real: 0.356395, d_loss_fake: 0.656419\n",
      "epoch: 19, batch: 144, g_loss: 0.935022, d_loss_real: 0.769388, d_loss_fake: 0.601649\n",
      "epoch: 20, batch: 144, g_loss: 0.969876, d_loss_real: 0.637140, d_loss_fake: 0.516273\n",
      "epoch: 21, batch: 144, g_loss: 0.870090, d_loss_real: 0.441589, d_loss_fake: 0.465188\n",
      "epoch: 22, batch: 144, g_loss: 1.054592, d_loss_real: 0.677766, d_loss_fake: 0.607874\n",
      "epoch: 23, batch: 144, g_loss: 0.936738, d_loss_real: 0.396789, d_loss_fake: 0.591339\n",
      "epoch: 24, batch: 144, g_loss: 0.793415, d_loss_real: 0.602161, d_loss_fake: 0.653604\n",
      "epoch: 25, batch: 144, g_loss: 0.882444, d_loss_real: 0.635513, d_loss_fake: 0.731378\n",
      "epoch: 26, batch: 144, g_loss: 0.919373, d_loss_real: 0.544648, d_loss_fake: 0.678308\n",
      "epoch: 27, batch: 144, g_loss: 0.851146, d_loss_real: 0.447493, d_loss_fake: 0.632743\n",
      "epoch: 28, batch: 144, g_loss: 0.767029, d_loss_real: 0.808414, d_loss_fake: 0.836866\n",
      "epoch: 29, batch: 144, g_loss: 0.822795, d_loss_real: 0.815536, d_loss_fake: 0.655481\n",
      "epoch: 30, batch: 144, g_loss: 0.757947, d_loss_real: 0.595293, d_loss_fake: 0.659223\n",
      "epoch: 31, batch: 144, g_loss: 0.738913, d_loss_real: 0.637966, d_loss_fake: 0.870959\n",
      "epoch: 32, batch: 144, g_loss: 0.770829, d_loss_real: 0.629101, d_loss_fake: 0.774958\n",
      "epoch: 33, batch: 144, g_loss: 0.751363, d_loss_real: 0.646689, d_loss_fake: 0.787224\n",
      "epoch: 34, batch: 144, g_loss: 0.691916, d_loss_real: 0.710688, d_loss_fake: 0.690136\n",
      "epoch: 35, batch: 144, g_loss: 0.692838, d_loss_real: 0.657610, d_loss_fake: 0.694506\n",
      "epoch: 36, batch: 144, g_loss: 0.709055, d_loss_real: 0.679756, d_loss_fake: 0.798996\n",
      "epoch: 37, batch: 144, g_loss: 0.699653, d_loss_real: 0.749885, d_loss_fake: 0.694087\n",
      "epoch: 38, batch: 144, g_loss: 0.691561, d_loss_real: 0.661550, d_loss_fake: 0.721026\n",
      "epoch: 39, batch: 144, g_loss: 0.686669, d_loss_real: 0.659413, d_loss_fake: 0.771568\n",
      "epoch: 40, batch: 144, g_loss: 0.721686, d_loss_real: 0.669492, d_loss_fake: 0.796001\n",
      "epoch: 41, batch: 144, g_loss: 0.705563, d_loss_real: 0.713562, d_loss_fake: 0.794428\n",
      "epoch: 42, batch: 144, g_loss: 0.672753, d_loss_real: 0.703295, d_loss_fake: 0.751111\n",
      "epoch: 43, batch: 144, g_loss: 0.699364, d_loss_real: 0.647841, d_loss_fake: 0.683555\n",
      "epoch: 44, batch: 144, g_loss: 0.651685, d_loss_real: 0.720582, d_loss_fake: 0.745175\n",
      "epoch: 45, batch: 144, g_loss: 0.734570, d_loss_real: 0.745625, d_loss_fake: 0.706784\n",
      "epoch: 46, batch: 144, g_loss: 0.700034, d_loss_real: 0.732495, d_loss_fake: 0.760345\n",
      "epoch: 47, batch: 144, g_loss: 0.688128, d_loss_real: 0.726135, d_loss_fake: 0.730601\n",
      "epoch: 48, batch: 144, g_loss: 0.708388, d_loss_real: 0.646361, d_loss_fake: 0.714278\n",
      "epoch: 49, batch: 144, g_loss: 0.675090, d_loss_real: 0.675705, d_loss_fake: 0.773769\n",
      "epoch: 50, batch: 144, g_loss: 0.698053, d_loss_real: 0.758777, d_loss_fake: 0.795397\n",
      "epoch: 51, batch: 144, g_loss: 0.683614, d_loss_real: 0.751575, d_loss_fake: 0.721079\n",
      "epoch: 52, batch: 144, g_loss: 0.693553, d_loss_real: 0.705034, d_loss_fake: 0.778831\n",
      "epoch: 53, batch: 144, g_loss: 0.658964, d_loss_real: 0.757566, d_loss_fake: 0.784975\n",
      "epoch: 54, batch: 144, g_loss: 0.669012, d_loss_real: 0.719333, d_loss_fake: 0.773549\n",
      "epoch: 55, batch: 144, g_loss: 0.700272, d_loss_real: 0.755088, d_loss_fake: 0.705301\n",
      "epoch: 56, batch: 144, g_loss: 0.714509, d_loss_real: 0.689200, d_loss_fake: 0.750743\n",
      "epoch: 57, batch: 144, g_loss: 0.712761, d_loss_real: 0.731123, d_loss_fake: 0.741387\n",
      "epoch: 58, batch: 144, g_loss: 0.691175, d_loss_real: 0.784322, d_loss_fake: 0.748555\n",
      "epoch: 59, batch: 144, g_loss: 0.709820, d_loss_real: 0.733227, d_loss_fake: 0.722714\n",
      "epoch: 60, batch: 144, g_loss: 0.712586, d_loss_real: 0.723460, d_loss_fake: 0.713079\n",
      "epoch: 61, batch: 144, g_loss: 0.684509, d_loss_real: 0.723786, d_loss_fake: 0.767661\n",
      "epoch: 62, batch: 144, g_loss: 0.697582, d_loss_real: 0.729587, d_loss_fake: 0.764007\n",
      "epoch: 63, batch: 144, g_loss: 0.693983, d_loss_real: 0.710837, d_loss_fake: 0.733400\n",
      "epoch: 64, batch: 144, g_loss: 0.708667, d_loss_real: 0.725541, d_loss_fake: 0.705121\n",
      "epoch: 65, batch: 144, g_loss: 0.705628, d_loss_real: 0.718140, d_loss_fake: 0.732527\n",
      "epoch: 66, batch: 144, g_loss: 0.709563, d_loss_real: 0.751258, d_loss_fake: 0.690948\n",
      "epoch: 67, batch: 144, g_loss: 0.699057, d_loss_real: 0.727263, d_loss_fake: 0.742177\n",
      "epoch: 68, batch: 144, g_loss: 0.680816, d_loss_real: 0.691270, d_loss_fake: 0.727938\n",
      "epoch: 69, batch: 144, g_loss: 0.703315, d_loss_real: 0.690921, d_loss_fake: 0.723418\n",
      "epoch: 70, batch: 144, g_loss: 0.721571, d_loss_real: 0.702404, d_loss_fake: 0.724368\n",
      "epoch: 71, batch: 144, g_loss: 0.711441, d_loss_real: 0.722650, d_loss_fake: 0.675419\n",
      "epoch: 72, batch: 144, g_loss: 0.677685, d_loss_real: 0.747935, d_loss_fake: 0.686015\n",
      "epoch: 73, batch: 144, g_loss: 0.712155, d_loss_real: 0.729427, d_loss_fake: 0.721608\n",
      "epoch: 74, batch: 144, g_loss: 0.683017, d_loss_real: 0.730255, d_loss_fake: 0.702541\n",
      "epoch: 75, batch: 144, g_loss: 0.699409, d_loss_real: 0.706749, d_loss_fake: 0.708899\n",
      "epoch: 76, batch: 144, g_loss: 0.700392, d_loss_real: 0.712784, d_loss_fake: 0.695965\n",
      "epoch: 77, batch: 144, g_loss: 0.730296, d_loss_real: 0.709347, d_loss_fake: 0.691318\n",
      "epoch: 78, batch: 144, g_loss: 0.702604, d_loss_real: 0.702578, d_loss_fake: 0.703260\n",
      "epoch: 79, batch: 144, g_loss: 0.711571, d_loss_real: 0.746375, d_loss_fake: 0.706275\n",
      "epoch: 80, batch: 144, g_loss: 0.703151, d_loss_real: 0.763866, d_loss_fake: 0.710386\n",
      "epoch: 81, batch: 144, g_loss: 0.717461, d_loss_real: 0.726645, d_loss_fake: 0.691011\n",
      "epoch: 82, batch: 144, g_loss: 0.720164, d_loss_real: 0.753795, d_loss_fake: 0.722606\n",
      "epoch: 83, batch: 144, g_loss: 0.715425, d_loss_real: 0.703105, d_loss_fake: 0.693696\n",
      "epoch: 84, batch: 144, g_loss: 0.721969, d_loss_real: 0.722861, d_loss_fake: 0.706994\n",
      "epoch: 85, batch: 144, g_loss: 0.728170, d_loss_real: 0.722297, d_loss_fake: 0.683348\n",
      "epoch: 86, batch: 144, g_loss: 0.703943, d_loss_real: 0.714313, d_loss_fake: 0.685596\n",
      "epoch: 87, batch: 144, g_loss: 0.702914, d_loss_real: 0.703095, d_loss_fake: 0.678182\n",
      "epoch: 88, batch: 144, g_loss: 0.700616, d_loss_real: 0.733217, d_loss_fake: 0.671986\n",
      "epoch: 89, batch: 144, g_loss: 0.706620, d_loss_real: 0.715476, d_loss_fake: 0.702200\n",
      "epoch: 90, batch: 144, g_loss: 0.703042, d_loss_real: 0.716933, d_loss_fake: 0.717140\n",
      "epoch: 91, batch: 144, g_loss: 0.714759, d_loss_real: 0.727988, d_loss_fake: 0.695862\n",
      "epoch: 92, batch: 144, g_loss: 0.700254, d_loss_real: 0.695542, d_loss_fake: 0.710964\n",
      "epoch: 93, batch: 144, g_loss: 0.717746, d_loss_real: 0.700680, d_loss_fake: 0.677551\n",
      "epoch: 94, batch: 144, g_loss: 0.696672, d_loss_real: 0.709341, d_loss_fake: 0.687477\n",
      "epoch: 95, batch: 144, g_loss: 0.690549, d_loss_real: 0.719916, d_loss_fake: 0.695854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96, batch: 144, g_loss: 0.696217, d_loss_real: 0.715918, d_loss_fake: 0.702012\n",
      "epoch: 97, batch: 144, g_loss: 0.723036, d_loss_real: 0.692101, d_loss_fake: 0.713209\n",
      "epoch: 98, batch: 144, g_loss: 0.720182, d_loss_real: 0.724701, d_loss_fake: 0.661513\n",
      "epoch: 99, batch: 144, g_loss: 0.711707, d_loss_real: 0.707443, d_loss_fake: 0.701165\n",
      "epoch: 100, batch: 144, g_loss: 0.682624, d_loss_real: 0.705585, d_loss_fake: 0.714912\n",
      "epoch: 101, batch: 144, g_loss: 0.719761, d_loss_real: 0.708992, d_loss_fake: 0.682296\n",
      "epoch: 102, batch: 144, g_loss: 0.711438, d_loss_real: 0.681098, d_loss_fake: 0.696607\n",
      "epoch: 103, batch: 144, g_loss: 0.691977, d_loss_real: 0.700339, d_loss_fake: 0.696848\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-93fd337a0d5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-0f1bc6a8b7bb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_noise\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m#noise = np.array([np.random.normal(0, 1, N_noise) for _ in range(BATCH_SIZE)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m  \u001b[1;33m==\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch: %d, batch: %d, g_loss: %f, d_loss_real: %f, d_loss_fake: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1104\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[0;32m   1105\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m                                          class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "これの結果に関わらず、篠原さんの課題にしよう"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
