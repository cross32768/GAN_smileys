{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzuk\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:916: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    }
   ],
   "source": [
    "DIRNAME = 'smileys_dataset_all_update/'\n",
    "SIZE = 32\n",
    "CHANNEL = 3\n",
    "files = os.listdir(DIRNAME)\n",
    "N_data = len(files) * 2\n",
    "train_data = np.zeros((N_data, SIZE, SIZE, CHANNEL))\n",
    "for i,file in enumerate(files):\n",
    "    im = Image.open(DIRNAME + file).convert('RGB').resize((SIZE, SIZE))\n",
    "    train_data[i] = np.array(im).astype(np.float32).reshape(SIZE,SIZE,CHANNEL)\n",
    "    train_data[i+len(files)] = train_data[i][:,::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzuk\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_noise = 100\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim = N_noise))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128 * 8 * 8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((128, 8, 8)))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size = 5, strides = 1, padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(3, kernel_size = 5, strides = 1, padding = 'same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size = 5, strides = 2, padding = 'same', input_shape = (CHANNEL, SIZE, SIZE)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Conv2D(128, kernel_size = 5, strides = 2))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "HALF_BATCH = int(BATCH_SIZE/2)\n",
    "NUM_EPOCH = 5000\n",
    "GENERATED_IMAGE_PATH = 'generated_images16/'\n",
    "if not os.path.exists(GENERATED_IMAGE_PATH):\n",
    "    os.mkdir(GENERATED_IMAGE_PATH)\n",
    "\n",
    "def train():\n",
    "    X_train = (train_data - 127.5) / 127.5\n",
    "    X_train = X_train.reshape(N_data, CHANNEL, SIZE, SIZE)\n",
    "    discriminator = discriminator_model()\n",
    "    # opt_d = SGD(lr = 5e-4, momentum = 0.9, nesterov = True)\n",
    "    opt_d = Adam(lr = 1e-5, beta_1 = 0.1)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=opt_d)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    generator = generator_model()\n",
    "    dcgan = Sequential([generator, discriminator])\n",
    "    opt_g = Adam(lr = 2e-5, beta_1 = 0.5)    \n",
    "    dcgan.compile(loss='binary_crossentropy', optimizer=opt_g)\n",
    "    \n",
    "    num_batches = int(N_data / BATCH_SIZE)\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        \n",
    "        for index in range(num_batches):\n",
    "            noise = np.array([np.random.uniform(-1, 1, N_noise) for _ in range(HALF_BATCH)])\n",
    "            #noise = np.array([np.random.normal(0, 1, N_noise) for _ in range(HALF_BATCH)])\n",
    "            image_batch = X_train[np.random.randint(0, N_data,HALF_BATCH)]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "        \n",
    "            if index == num_batches - 1 and epoch % 2 == 0:\n",
    "                for n,image in enumerate(generated_images):\n",
    "                    image = image*127.5 + 127.5\n",
    "                    Image.fromarray(image.astype(np.uint8).reshape(SIZE,SIZE,CHANNEL)) \\\n",
    "                                                      .save(GENERATED_IMAGE_PATH+\"%03d_%03d.png\" % (epoch, n))\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(image_batch, np.random.uniform(1, 1,HALF_BATCH))\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, np.random.uniform(0, 0, HALF_BATCH))\n",
    "            noise = np.array([np.random.uniform(-1, 1, N_noise) for _ in range(BATCH_SIZE)])\n",
    "            #noise = np.array([np.random.normal(0, 1, N_noise) for _ in range(BATCH_SIZE)])\n",
    "            g_loss = dcgan.train_on_batch(noise, np.random.uniform(1, 1, BATCH_SIZE))\n",
    "            if index  == num_batches - 1:\n",
    "                print(\"epoch: %d, batch: %d, g_loss: %f, d_loss_real: %f, d_loss_fake: %f\" % (epoch, index, g_loss, d_loss_real, d_loss_fake))\n",
    "    generator.save_weights('generator5.h5')\n",
    "    discriminator.save_weights('discriminator5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzuk\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
